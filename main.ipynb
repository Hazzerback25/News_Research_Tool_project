{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit -q"
      ],
      "metadata": {
        "id": "YNNigvMkSiqs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain -q"
      ],
      "metadata": {
        "id": "7mGAigFBSYQj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install unstructured -q"
      ],
      "metadata": {
        "id": "R-ldC8SloBLC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken -q"
      ],
      "metadata": {
        "id": "HExCf-KM9uTt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu -q"
      ],
      "metadata": {
        "id": "MOaooiq3-Jus"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install typing-extensions==3.10.0.2-q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "MUne-_sSVc4a",
        "outputId": "dd422977-6b70-4df2-bc5b-6f2d7d4a8054"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing-extensions==3.10.0.2\n",
            "  Using cached typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.9.0\n",
            "    Uninstalling typing_extensions-4.9.0:\n",
            "      Successfully uninstalled typing_extensions-4.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "sqlalchemy 2.0.23 requires typing-extensions>=4.2.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "arviz 0.15.1 requires typing-extensions>=4.1.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "chex 0.1.7 requires typing-extensions>=4.2.0; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "fastapi 0.105.0 requires typing-extensions>=4.8.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "flax 0.7.5 requires typing-extensions>=4.2, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "gradio 4.10.0 requires typing-extensions~=4.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "gradio-client 0.7.3 requires typing-extensions~=4.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "ibis-framework 6.2.0 requires typing-extensions<5,>=4.3.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "librosa 0.10.1 requires typing-extensions>=4.1.1, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "openai 1.5.0 requires typing-extensions<5,>=4.5, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "polars 0.17.3 requires typing_extensions>=4.0.1; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "pydantic 2.5.2 requires typing-extensions>=4.6.1, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "pydantic-core 2.14.5 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "python-utils 3.8.1 requires typing-extensions>3.10.0.2, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "streamlit 1.29.0 requires typing-extensions<5,>=4.3.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "unstructured-client 0.15.0 requires typing-extensions>=4.7.1, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "uvicorn 0.24.0.post1 requires typing-extensions>=4.0; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typing-extensions-3.10.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show typing_extensions"
      ],
      "metadata": {
        "id": "cU9bgau6WUNx",
        "outputId": "c09d8645-e319-4a2f-a219-cadb21fd6ec3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: typing-extensions\n",
            "Version: 3.10.0.2\n",
            "Summary: Backported and Experimental Type Hints for Python 3.5+\n",
            "Home-page: https://github.com/python/typing/blob/master/typing_extensions/README.rst\n",
            "Author: Guido van Rossum, Jukka Lehtosalo, Łukasz Langa, Michael Lee\n",
            "Author-email: levkivskyi@gmail.com\n",
            "License: PSF\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: arviz, chex, fastapi, flax, gradio, gradio_client, huggingface-hub, ibis-framework, inflect, librosa, openai, orbax-checkpoint, panel, polars, pydantic, pydantic_core, pymc, pytensor, python-utils, qudida, SQLAlchemy, streamlit, tensorflow, tensorflow-probability, torch, typer, typing-inspect, unstructured, unstructured-client, uvicorn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rXjUBdqB7Qu",
        "outputId": "287fbeeb-346e-4ba1-9971-bceb973acbfe"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.10.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.105.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n",
            "Requirement already satisfied: gradio-client==0.7.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.7.3)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.19.4)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.5.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Collecting typing-extensions~=4.0 (from gradio)\n",
            "  Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.0.post1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.3->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.3->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.14.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.27.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typing-extensions-4.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rQLaOoy9_EF",
        "outputId": "9f945b2d-07b9-4c0e-db9d-b557b47519d7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.5.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.14.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JXbyjDLNSKyb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import time\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "key=userdata.get('OPENAI_API_KEY')\n",
        "#os.environ[\"OPENAI_API_KEY\"] = key"
      ],
      "metadata": {
        "id": "R3wH7c8DSpsb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRPGDRBGXFi1",
        "outputId": "7c2ab0f4-c289-40f8-b7fb-86bb214fcad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.150.133.101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio"
      ],
      "metadata": {
        "id": "OwulEBkWV5Wk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(url1,url2,url3,queryInput):\n",
        "  urls=[]\n",
        "  #for i in range(3):\n",
        "   # url=input(f\"enter url {i}\")\n",
        "    #urls.append(url)\n",
        "  urls=[url1,url2,url3]\n",
        "\n",
        "  #data-loading\n",
        "  loader=UnstructuredURLLoader(urls=urls)\n",
        "  data=loader.load()\n",
        "\n",
        "  #data splitting\n",
        "  text_splitter=RecursiveCharacterTextSplitter(\n",
        "    separators=['\\n\\n' , '\\n' , '.' , ','],\n",
        "    chunk_size=1000\n",
        "  )\n",
        "\n",
        "  docs = text_splitter.split_documents(data)\n",
        "\n",
        "  #creating and saving embeddings to FAISS Index\n",
        "\n",
        "  embeddings=OpenAIEmbeddings()\n",
        "  vectorstore_openai=FAISS.from_documents(docs,embeddings)\n",
        "\n",
        "  vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "  query=queryInput\n",
        "  llm = OpenAI(temperature=0.9, max_tokens=500)\n",
        "  chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorstore.as_retriever())\n",
        "  result = chain({\"question\": query}, return_only_outputs=True)\n",
        "  ans=result[\"answer\"]\n",
        "  return ans"
      ],
      "metadata": {
        "id": "LqIU9yR08wze"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface=gradio.Interface(fn=main ,inputs=['text','text','text','text'],outputs=['text'])\n"
      ],
      "metadata": {
        "id": "IrD5_elMSxTo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "isMqwYN4T9Dp",
        "outputId": "67973ecb-1230-44cf-a408-3fa3b45527d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://974dfe018594e2eb41.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://974dfe018594e2eb41.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:langchain_community.document_loaders.url:Error fetching or processing https://www.moneycontrol.com/news/business/markets/adani-stocks-rally-continues-surge-up-to-16-as-us-agency-calls-hindenburg-charges-irrelevant-11861611.html, exception: Could not determine delimiter\n",
            "ERROR:langchain_community.document_loaders.url:Error fetching or processing https://www.moneycontrol.com/news/business/markets/adani-stocks-rally-continues-surge-up-to-16-as-us-agency-calls-hindenburg-charges-irrelevant-11861611.html, exception: Could not determine delimiter\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 459, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1533, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1151, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 678, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-12-bdb9f34ac67e>\", line 25, in main\n",
            "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py\", line 510, in from_documents\n",
            "    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/faiss.py\", line 914, in from_texts\n",
            "    embeddings = embedding.embed_documents(texts)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 667, in embed_documents\n",
            "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 493, in _get_len_safe_embeddings\n",
            "    response = embed_with_retry(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 115, in embed_with_retry\n",
            "    return embeddings.client.create(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/embeddings.py\", line 106, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1088, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 853, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 916, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 958, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 916, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 958, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 930, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-ada-002 in organization org-OootWkYSha3vcTypN4e9f0ND on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 459, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1533, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1151, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 678, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-12-bdb9f34ac67e>\", line 25, in main\n",
            "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py\", line 510, in from_documents\n",
            "    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/faiss.py\", line 914, in from_texts\n",
            "    embeddings = embedding.embed_documents(texts)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 667, in embed_documents\n",
            "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 493, in _get_len_safe_embeddings\n",
            "    response = embed_with_retry(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 115, in embed_with_retry\n",
            "    return embeddings.client.create(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/embeddings.py\", line 106, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1088, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 853, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 916, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 958, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 916, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 958, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 930, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-ada-002 in organization org-OootWkYSha3vcTypN4e9f0ND on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 497, in process_events\n",
            "    response = await self.call_prediction(awake_events, batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 468, in call_prediction\n",
            "    raise Exception(str(error) if show_error else None) from error\n",
            "Exception: None\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 459, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1533, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1151, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 678, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-12-bdb9f34ac67e>\", line 25, in main\n",
            "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py\", line 510, in from_documents\n",
            "    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/faiss.py\", line 914, in from_texts\n",
            "    embeddings = embedding.embed_documents(texts)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 667, in embed_documents\n",
            "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 493, in _get_len_safe_embeddings\n",
            "    response = embed_with_retry(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 115, in embed_with_retry\n",
            "    return embeddings.client.create(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/embeddings.py\", line 106, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1088, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 853, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 916, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 958, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 916, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 958, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 930, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-ada-002 in organization org-OootWkYSha3vcTypN4e9f0ND on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 459, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1533, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1151, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 678, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-12-bdb9f34ac67e>\", line 25, in main\n",
            "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py\", line 510, in from_documents\n",
            "    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/faiss.py\", line 914, in from_texts\n",
            "    embeddings = embedding.embed_documents(texts)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 667, in embed_documents\n",
            "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 493, in _get_len_safe_embeddings\n",
            "    response = embed_with_retry(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 115, in embed_with_retry\n",
            "    return embeddings.client.create(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/embeddings.py\", line 106, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1088, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 853, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 916, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 958, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 916, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 958, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 930, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-ada-002 in organization org-OootWkYSha3vcTypN4e9f0ND on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 497, in process_events\n",
            "    response = await self.call_prediction(awake_events, batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 468, in call_prediction\n",
            "    raise Exception(str(error) if show_error else None) from error\n",
            "Exception: None\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 459, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1533, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1151, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 678, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-12-bdb9f34ac67e>\", line 30, in main\n",
            "    result = chain({\"question\": query}, return_only_outputs=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 312, in __call__\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 306, in __call__\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/qa_with_sources/base.py\", line 152, in _call\n",
            "    docs = self._get_docs(inputs, run_manager=_run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/qa_with_sources/retrieval.py\", line 49, in _get_docs\n",
            "    docs = self.retriever.get_relevant_documents(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/retrievers.py\", line 211, in get_relevant_documents\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/retrievers.py\", line 204, in get_relevant_documents\n",
            "    result = self._get_relevant_documents(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py\", line 656, in _get_relevant_documents\n",
            "    docs = self.vectorstore.similarity_search(query, **self.search_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/faiss.py\", line 512, in similarity_search\n",
            "    docs_and_scores = self.similarity_search_with_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/faiss.py\", line 393, in similarity_search_with_score\n",
            "    embedding = self._embed_query(query)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/faiss.py\", line 156, in _embed_query\n",
            "    return self.embedding_function.embed_query(text)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 696, in embed_query\n",
            "    return self.embed_documents([text])[0]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 667, in embed_documents\n",
            "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 493, in _get_len_safe_embeddings\n",
            "    response = embed_with_retry(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 115, in embed_with_retry\n",
            "    return embeddings.client.create(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/embeddings.py\", line 106, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1088, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 853, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 916, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 958, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 916, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 958, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 930, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-ada-002 in organization org-OootWkYSha3vcTypN4e9f0ND on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 459, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1533, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1151, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 678, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-12-bdb9f34ac67e>\", line 30, in main\n",
            "    result = chain({\"question\": query}, return_only_outputs=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 312, in __call__\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 306, in __call__\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/qa_with_sources/base.py\", line 152, in _call\n",
            "    docs = self._get_docs(inputs, run_manager=_run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/qa_with_sources/retrieval.py\", line 49, in _get_docs\n",
            "    docs = self.retriever.get_relevant_documents(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/retrievers.py\", line 211, in get_relevant_documents\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/retrievers.py\", line 204, in get_relevant_documents\n",
            "    result = self._get_relevant_documents(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py\", line 656, in _get_relevant_documents\n",
            "    docs = self.vectorstore.similarity_search(query, **self.search_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/faiss.py\", line 512, in similarity_search\n",
            "    docs_and_scores = self.similarity_search_with_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/faiss.py\", line 393, in similarity_search_with_score\n",
            "    embedding = self._embed_query(query)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/faiss.py\", line 156, in _embed_query\n",
            "    return self.embedding_function.embed_query(text)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 696, in embed_query\n",
            "    return self.embed_documents([text])[0]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 667, in embed_documents\n",
            "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 493, in _get_len_safe_embeddings\n",
            "    response = embed_with_retry(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\", line 115, in embed_with_retry\n",
            "    return embeddings.client.create(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/embeddings.py\", line 106, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1088, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 853, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 916, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 958, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 916, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 958, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 930, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for text-embedding-ada-002 in organization org-OootWkYSha3vcTypN4e9f0ND on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 497, in process_events\n",
            "    response = await self.call_prediction(awake_events, batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 468, in call_prediction\n",
            "    raise Exception(str(error) if show_error else None) from error\n",
            "Exception: None\n"
          ]
        }
      ]
    }
  ]
}